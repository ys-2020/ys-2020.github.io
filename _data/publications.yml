main:

  - title: "Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter"
    authors: Qinghao Hu*, <strong>Shang Yang*</strong>, Junxian Guo, Xiaozhe Yao, Yujun Lin, Yuxian Gu, Han Cai, Chuang Gan, Ana Klimovic, Song Han
    conference_short: ASPLOS
    conference: The 31th International Conference on Architectural Support for Programming Languages and Operating Systems <strong>(ASPLOS)</strong>, 2026. 
    paper: https://arxiv.org/abs/2511.16665
    code: https://github.com/mit-han-lab/fastrl
    image: ./assets/img/paper_teasers/TLT.png

  - title: "LServe: Efficient Long-sequence LLM Serving with Unified Sparse Attention"
    authors: <strong>Shang Yang*</strong>, Junxian Guo*, Haotian Tang, Qinghao Hu, Guangxuan Xiao, Jiaming Tang, Yujun Lin, Zhijian Liu, Yao Lu, Song Han.
    conference_short: MLSys
    conference: The Eighth Annual Conference on Machine Learning and Systems <strong>(MLSys)</strong>, 2025. 
    paper: https://arxiv.org/abs/2502.14866
    code: https://github.com/mit-han-lab/omniserve
    image: ./assets/img/paper_teasers/LServe.png

  - title: "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving"
    authors: Yujun Lin*, Haotian Tang*, <strong>Shang Yang*</strong>, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, Song Han.
    conference_short: MLSys
    conference: The Eighth Annual Conference on Machine Learning and Systems <strong>(MLSys)</strong>, 2025. 
    paper: https://arxiv.org/abs/2405.04532
    code: https://github.com/mit-han-lab/omniserve
    image: ./assets/img/paper_teasers/QServe.png

  - title: "AWQ: Activation-aware Weight Quantization for On-Device LLM Compression and Acceleration"
    authors: Ji Lin*, Jiaming Tang*, Haotian Tang†, <strong>Shang Yang†</strong>, Wei-Ming Chen, Wei-Chen Wang, Guangxuan Xiao, Xingyu Dang, Chuang Gan, Song Han.
    conference_short: MLSys
    conference: The Seventh Annual Conference on Machine Learning and Systems <strong>(MLSys)</strong>, 2024. 
    paper: https://arxiv.org/abs/2306.00978
    code: https://github.com/mit-han-lab/llm-awq
    image: ./assets/img/paper_teasers/awq_tinychat.png
    notes: Best Paper Award

  - title: "TorchSparse++: Efficient Training and Inference Framework for Sparse Convolution on GPUs"
    authors: Haotian Tang*, <strong>Shang Yang*</strong>, Zhijian Liu, Ke Hong, Zhongming Yu, Xiuyu Li, Guohao Dai, Yu Wang, Song Han.
    conference_short: MICRO
    conference: 56th IEEE/ACM International Symposium on Microarchitecture <strong>(MICRO)</strong>, 2023.
    paper: https://www.dropbox.com/scl/fi/obdku0kqxjlkvuom2opk4/paper.pdf?rlkey=0zmy8eq9fzllgkx54zsvwsecf&dl=0
    code: https://github.com/mit-han-lab/torchsparse
    image: ./assets/img/paper_teasers/torchsparsepp.png
