---
layout: homepage
---

## Shang Yang

I am a third-year Ph.D. student at [HAN LAB](https://hanlab.mit.edu/) of [MIT EECS](https://eecs.mit.edu/), advised by [Prof. Song Han](https://songhan.mit.edu/). My long-term goal is to build efficient machine learning systems for applications at different scales, especially the Large Language Models (LLMs). Recently, I am activately working on the efficient inference systems for LLMs/VLMs.


## News
- **[2025/11]** üèÜ [TLT](https://arxiv.org/abs/2511.16665), our efficient RL framework for reasoning LLMs, has been accepted by [ASPLOS 2026](https://www.asplos-conference.org/asplos2026/)!
- **[2025/05]** üî• I presented [QServe](https://arxiv.org/abs/2405.04532) and [LServe](https://arxiv.org/abs/2502.14866) at [MLSys 2025](https://mlsys.org/Conferences/2025)! [[QServe Video](https://www.youtube.com/watch?v=BipXPh47ILQ&t=78s)] / [[LServe Video](https://www.youtube.com/watch?v=mx4lHNfwbM0&t=2s)]
- **[2025/02]** üèÜ Both [QServe](https://arxiv.org/abs/2405.04532) and [LServe](https://arxiv.org/abs/2502.14866) have been accepted by [MLSys 2025](https://mlsys.org/Conferences/2025)!
- **[2025/02]** üî• We released [LServe](https://hanlab.mit.edu/projects/lserve), substantially accelerating long-sequence LLM inference with Unified Sparse Attention.
- **[2024/05]** üî• We released [QServe](https://hanlab.mit.edu/projects/qserve), an efficient large-scale LLM serving framework with W4A8KV4 Quantization.
- **[2024/05]** üèÜ [AWQ&TinyChat](https://arxiv.org/abs/2306.00978) receives the **Best Paper Award** of [MLSys 2024](https://mlsys.org/Conferences/2024)!
- **[2024/03]** We have released an updated version of [TinyChat](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat#tinychat-efficient-and-lightweight-chatbot-with-awq). Visual Language Models (e.g. [VILA](https://github.com/Efficient-Large-Model/VILA)) are supported! Play with our [demo](https://vila.hanlab.ai)!
- **[2024/02]** üî• [AWQ](https://arxiv.org/abs/2306.00978) is accepted by [MLSys 2024](https://mlsys.org/Conferences/2024)!
- **[2023/10]** üî• I presented [TorchSparse++](https://www.dropbox.com/scl/fi/obdku0kqxjlkvuom2opk4/paper.pdf?rlkey=0zmy8eq9fzllgkx54zsvwsecf&dl=0) at [MICRO 2023](https://microarch.org/micro56/)! See the [video](https://www.youtube.com/watch?v=4gKYE9-YtP0) and [slides](https://www.dropbox.com/scl/fi/1004eifd5fjethuv089z0/torchsparse_micro23_slides.pdf?rlkey=vugxz974g87j4fxs0fivmysjp&dl=0) here!

{% include_relative _includes/publications.md %}

{% include_relative _includes/blogs.md %}

{% include_relative _includes/services.md %}
